{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:46:15.092259Z",
     "iopub.status.busy": "2024-09-29T09:46:15.091950Z",
     "iopub.status.idle": "2024-09-29T09:46:32.601786Z",
     "shell.execute_reply": "2024-09-29T09:46:32.600997Z",
     "shell.execute_reply.started": "2024-09-29T09:46:15.092220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import onnx\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import kagglehub as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: kagglehub in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\karthik\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (4.25.7)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\karthik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx) (4.13.2)\n"
     ]
    }
   ],
   "source": [
    "pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "3                            0.0.0\n",
      "absl-py                      2.2.2\n",
      "altair                       5.5.0\n",
      "asttokens                    3.0.0\n",
      "astunparse                   1.6.3\n",
      "attrs                        25.3.0\n",
      "blinker                      1.9.0\n",
      "cachetools                   5.5.2\n",
      "certifi                      2025.1.31\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.4.1\n",
      "click                        8.1.8\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "contourpy                    1.3.2\n",
      "cv                           1.0.0\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.14\n",
      "decorator                    5.2.1\n",
      "exceptiongroup               1.2.2\n",
      "executing                    2.2.0\n",
      "filelock                     3.18.0\n",
      "flatbuffers                  25.2.10\n",
      "fonttools                    4.57.0\n",
      "fsspec                       2025.3.2\n",
      "gast                         0.4.0\n",
      "gitdb                        4.0.12\n",
      "GitPython                    3.1.44\n",
      "google-auth                  2.39.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.71.0\n",
      "h5py                         3.13.0\n",
      "idna                         3.10\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.35.0\n",
      "jax                          0.5.3\n",
      "jaxlib                       0.5.3\n",
      "jedi                         0.19.2\n",
      "Jinja2                       3.1.6\n",
      "joblib                       1.4.2\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2025.4.1\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.7.2\n",
      "kagglehub                    0.3.12\n",
      "keras                        3.9.2\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.8\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.8\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   3.0.2\n",
      "matplotlib                   3.10.1\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "mediapipe                    0.10.21\n",
      "ml_dtypes                    0.5.1\n",
      "mpmath                       1.3.0\n",
      "namex                        0.0.8\n",
      "narwhals                     1.36.0\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.4.2\n",
      "nltk                         3.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "onnx                         1.18.0\n",
      "opencv-contrib-python        4.11.0.86\n",
      "opencv-python                4.11.0.86\n",
      "opt_einsum                   3.4.0\n",
      "optree                       0.15.0\n",
      "packaging                    24.2\n",
      "panda                        0.3.1\n",
      "pandas                       2.2.3\n",
      "parso                        0.8.4\n",
      "pillow                       11.2.1\n",
      "pip                          25.0.1\n",
      "platformdirs                 4.3.7\n",
      "preprocessing                0.1.13\n",
      "prompt_toolkit               3.0.51\n",
      "protobuf                     4.25.7\n",
      "psutil                       7.0.0\n",
      "pure_eval                    0.2.3\n",
      "pyarrow                      20.0.0\n",
      "pyasn1                       0.6.1\n",
      "pyasn1_modules               0.4.2\n",
      "pycparser                    2.22\n",
      "pydeck                       0.9.1\n",
      "Pygments                     2.19.1\n",
      "pyparsing                    3.2.3\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2025.2\n",
      "pywin32                      310\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        26.4.0\n",
      "referencing                  0.36.2\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "rich                         14.0.0\n",
      "rpds-py                      0.24.0\n",
      "rsa                          4.9.1\n",
      "scikit-learn                 1.6.1\n",
      "scipy                        1.15.2\n",
      "sentencepiece                0.2.0\n",
      "setuptools                   65.5.0\n",
      "six                          1.17.0\n",
      "smmap                        5.0.2\n",
      "sounddevice                  0.5.1\n",
      "sphinx-rtd-theme             0.2.4\n",
      "stack-data                   0.6.3\n",
      "streamlit                    1.44.1\n",
      "sympy                        1.14.0\n",
      "tenacity                     9.1.2\n",
      "tensorboard                  2.19.0\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.19.0\n",
      "tensorflow-estimator         2.9.0\n",
      "tensorflow_intel             2.18.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    3.0.1\n",
      "threadpoolctl                3.6.0\n",
      "toml                         0.10.2\n",
      "torch                        2.7.0\n",
      "torchaudio                   2.7.0\n",
      "torchvision                  0.22.0\n",
      "tornado                      6.4.2\n",
      "tqdm                         4.67.1\n",
      "traitlets                    5.14.3\n",
      "typing_extensions            4.13.2\n",
      "tzdata                       2025.2\n",
      "urllib3                      2.4.0\n",
      "watchdog                     6.0.0\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     3.1.3\n",
      "wheel                        0.45.1\n",
      "wrapt                        1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 1894776832 bytes (1002932355 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/vipoooool/new-plant-diseases-dataset?dataset_version_number=2 (1894776832/2897709187) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.70G/2.70G [05:19<00:00, 3.14MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Karthik\\.cache\\kagglehub\\datasets\\vipoooool\\new-plant-diseases-dataset\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\",force_download=True)\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:46:37.251202Z",
     "iopub.status.busy": "2024-09-29T09:46:37.250115Z",
     "iopub.status.idle": "2024-09-29T09:46:37.265790Z",
     "shell.execute_reply": "2024-09-29T09:46:37.264961Z",
     "shell.execute_reply.started": "2024-09-29T09:46:37.251006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes:\n",
      "Apple___Apple_scab\n",
      "Apple___Black_rot\n",
      "Apple___Cedar_apple_rust\n",
      "Apple___healthy\n",
      "Blueberry___healthy\n",
      "Cherry_(including_sour)___healthy\n",
      "Cherry_(including_sour)___Powdery_mildew\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Corn_(maize)___Common_rust_\n",
      "Corn_(maize)___healthy\n",
      "Corn_(maize)___Northern_Leaf_Blight\n",
      "Grape___Black_rot\n",
      "Grape___Esca_(Black_Measles)\n",
      "Grape___healthy\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Orange___Haunglongbing_(Citrus_greening)\n",
      "Peach___Bacterial_spot\n",
      "Peach___healthy\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Pepper,_bell___healthy\n",
      "Potato___Early_blight\n",
      "Potato___healthy\n",
      "Potato___Late_blight\n",
      "Raspberry___healthy\n",
      "Soybean___healthy\n",
      "Squash___Powdery_mildew\n",
      "Strawberry___healthy\n",
      "Strawberry___Leaf_scorch\n",
      "Tomato___Bacterial_spot\n",
      "Tomato___Early_blight\n",
      "Tomato___healthy\n",
      "Tomato___Late_blight\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Septoria_leaf_spot\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Tomato___Target_Spot\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# # The path to the main directory \n",
    "# main_dir = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'  \n",
    "\n",
    "# # List all classes in the main directory\n",
    "# classes = [d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
    "\n",
    "\n",
    "# The correct path to the main directory on your local machine\n",
    "# We need to append the subdirectories based on the dataset's structure\n",
    "main_dir = os.path.join(path, 'New Plant Diseases Dataset(Augmented)', 'New Plant Diseases Dataset(Augmented)', 'train')\n",
    "\n",
    "# List all classes in the main directory\n",
    "classes = [d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
    "# Print the names of the classes\n",
    "print(\"\\nClasses:\")\n",
    "for class_name in classes:\n",
    "    print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:46:41.745832Z",
     "iopub.status.busy": "2024-09-29T09:46:41.745162Z",
     "iopub.status.idle": "2024-09-29T09:55:18.583713Z",
     "shell.execute_reply": "2024-09-29T09:55:18.582703Z",
     "shell.execute_reply.started": "2024-09-29T09:46:41.745786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying selected subdirectories to: d:\\Capstone_MiniProjects_Guvi\\Final_Pros\\Plant-Disease-Detection-from-Images-main\\Plant-Disease-Detection-from-Images-main\\plant_diseases_subset\n",
      "Copied 'Apple___Apple_scab'\n",
      "Copied 'Apple___Black_rot'\n",
      "Copied 'Apple___Cedar_apple_rust'\n",
      "Copied 'Apple___healthy'\n",
      "Copied 'Blueberry___healthy'\n",
      "Copied 'Cherry_(including_sour)___healthy'\n",
      "Copied 'Cherry_(including_sour)___Powdery_mildew'\n",
      "Copied 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot'\n",
      "Copied 'Corn_(maize)___Common_rust_'\n",
      "Copied 'Corn_(maize)___healthy'\n",
      "Copied 'Corn_(maize)___Northern_Leaf_Blight'\n",
      "Copied 'Grape___Black_rot'\n",
      "Copied 'Grape___Esca_(Black_Measles)'\n",
      "Copied 'Grape___healthy'\n",
      "Copied 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'\n",
      "Copied 'Orange___Haunglongbing_(Citrus_greening)'\n",
      "Copied 'Peach___Bacterial_spot'\n",
      "Copied 'Peach___healthy'\n",
      "Copied 'Pepper,_bell___Bacterial_spot'\n",
      "Copied 'Pepper,_bell___healthy'\n",
      "Copied 'Potato___Early_blight'\n",
      "Copied 'Potato___healthy'\n",
      "Copied 'Potato___Late_blight'\n",
      "Copied 'Raspberry___healthy'\n",
      "Copied 'Soybean___healthy'\n",
      "Copied 'Squash___Powdery_mildew'\n",
      "Copied 'Strawberry___healthy'\n",
      "Copied 'Strawberry___Leaf_scorch'\n",
      "Copied 'Tomato___Bacterial_spot'\n",
      "Copied 'Tomato___Early_blight'\n",
      "Copied 'Tomato___healthy'\n",
      "Copied 'Tomato___Late_blight'\n",
      "Copied 'Tomato___Leaf_Mold'\n",
      "Copied 'Tomato___Septoria_leaf_spot'\n",
      "Copied 'Tomato___Spider_mites Two-spotted_spider_mite'\n",
      "Copied 'Tomato___Target_Spot'\n",
      "Copied 'Tomato___Tomato_mosaic_virus'\n",
      "Copied 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      "\n",
      "Subdirectories ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'] copied to d:\\Capstone_MiniProjects_Guvi\\Final_Pros\\Plant-Disease-Detection-from-Images-main\\Plant-Disease-Detection-from-Images-main\\plant_diseases_subset\n",
      "You can find the copied data at: d:\\Capstone_MiniProjects_Guvi\\Final_Pros\\Plant-Disease-Detection-from-Images-main\\Plant-Disease-Detection-from-Images-main\\plant_diseases_subset\n"
     ]
    }
   ],
   "source": [
    "# # List the classes to work on\n",
    "# # subdirs_to_copy = ['Grape___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot','Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___Black_rot','Corn_(maize)___Common_rust_','Grape___Esca_(Black_Measles)','Corn_(maize)___healthy']  \n",
    "# subdirs_to_copy = classes\n",
    "# # Create a new directory in the Kaggle working directory\n",
    "# subset_dir = '/kaggle/working/new_directory'\n",
    "# os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "# # Copy the selected classes to the new directory\n",
    "# for subdir_name in subdirs_to_copy:\n",
    "#     src_dir_path = os.path.join(main_dir, subdir_name)\n",
    "#     dest_dir_path = os.path.join(subset_dir, subdir_name)\n",
    "#     shutil.copytree(src_dir_path, dest_dir_path)\n",
    "\n",
    "# print(f\"Subdirectories {subdirs_to_copy} copied to {subset_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# List the classes to work on\n",
    "subdirs_to_copy = classes # Using all detected classes as per your request\n",
    "\n",
    "# Create a new directory in the current working directory for the subset\n",
    "# This will create a 'plant_diseases_subset' folder where you run this script\n",
    "subset_dir = os.path.join(os.getcwd(), 'plant_diseases_subset')\n",
    "os.makedirs(subset_dir, exist_ok=True) # Use exist_ok=True to avoid error if directory already exists\n",
    "\n",
    "# Copy the selected classes to the new directory\n",
    "print(f\"\\nCopying selected subdirectories to: {subset_dir}\")\n",
    "for subdir_name in subdirs_to_copy:\n",
    "    src_dir_path = os.path.join(main_dir, subdir_name)\n",
    "    dest_dir_path = os.path.join(subset_dir, subdir_name)\n",
    "\n",
    "    # Check if the source directory exists before attempting to copy\n",
    "    if os.path.exists(src_dir_path) and os.path.isdir(src_dir_path):\n",
    "        # Remove destination if it exists to ensure a clean copy, especially if force_download was used\n",
    "        if os.path.exists(dest_dir_path):\n",
    "            shutil.rmtree(dest_dir_path)\n",
    "        shutil.copytree(src_dir_path, dest_dir_path)\n",
    "        print(f\"Copied '{subdir_name}'\")\n",
    "    else:\n",
    "        print(f\"Warning: Source directory '{src_dir_path}' not found. Skipping.\")\n",
    "\n",
    "\n",
    "print(f\"\\nSubdirectories {subdirs_to_copy} copied to {subset_dir}\")\n",
    "print(f\"You can find the copied data at: {subset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:24.588367Z",
     "iopub.status.busy": "2024-09-29T09:55:24.587495Z",
     "iopub.status.idle": "2024-09-29T09:55:24.713538Z",
     "shell.execute_reply": "2024-09-29T09:55:24.712586Z",
     "shell.execute_reply.started": "2024-09-29T09:55:24.588323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 70295\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter for the number of images\n",
    "image_count = 0\n",
    "\n",
    "# Iterate over all classes and count the images\n",
    "for subdir, _, files in os.walk(subset_dir):\n",
    "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n",
    "    image_count += len(image_files)\n",
    "\n",
    "print(f\"Total number of images: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:35.485086Z",
     "iopub.status.busy": "2024-09-29T09:55:35.484699Z",
     "iopub.status.idle": "2024-09-29T09:55:35.489651Z",
     "shell.execute_reply": "2024-09-29T09:55:35.488591Z",
     "shell.execute_reply.started": "2024-09-29T09:55:35.485048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#dataset_path = '/kaggle/working/new_directory'\n",
    "dataset_path = 'd:\\Capstone_MiniProjects_Guvi\\Final_Pros\\Plant-Disease-Detection-from-Images-main\\Plant-Disease-Detection-from-Images-main\\plant_diseases_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:39.473636Z",
     "iopub.status.busy": "2024-09-29T09:55:39.472894Z",
     "iopub.status.idle": "2024-09-29T09:55:39.479029Z",
     "shell.execute_reply": "2024-09-29T09:55:39.477991Z",
     "shell.execute_reply.started": "2024-09-29T09:55:39.473596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),              # resize all images to 150x150 pixels\n",
    "    transforms.ToTensor(),                      # convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:46.855695Z",
     "iopub.status.busy": "2024-09-29T09:55:46.855267Z",
     "iopub.status.idle": "2024-09-29T09:55:47.185753Z",
     "shell.execute_reply": "2024-09-29T09:55:47.185012Z",
     "shell.execute_reply.started": "2024-09-29T09:55:46.855647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T10:26:28.458415Z",
     "iopub.status.busy": "2024-09-29T10:26:28.458042Z",
     "iopub.status.idle": "2024-09-29T10:26:28.465624Z",
     "shell.execute_reply": "2024-09-29T10:26:28.464714Z",
     "shell.execute_reply.started": "2024-09-29T10:26:28.458379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple___Apple_scab',\n",
       " 'Apple___Black_rot',\n",
       " 'Apple___Cedar_apple_rust',\n",
       " 'Apple___healthy',\n",
       " 'Blueberry___healthy',\n",
       " 'Cherry_(including_sour)___Powdery_mildew',\n",
       " 'Cherry_(including_sour)___healthy',\n",
       " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
       " 'Corn_(maize)___Common_rust_',\n",
       " 'Corn_(maize)___Northern_Leaf_Blight',\n",
       " 'Corn_(maize)___healthy',\n",
       " 'Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy',\n",
       " 'Orange___Haunglongbing_(Citrus_greening)',\n",
       " 'Peach___Bacterial_spot',\n",
       " 'Peach___healthy',\n",
       " 'Pepper,_bell___Bacterial_spot',\n",
       " 'Pepper,_bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Raspberry___healthy',\n",
       " 'Soybean___healthy',\n",
       " 'Squash___Powdery_mildew',\n",
       " 'Strawberry___Leaf_scorch',\n",
       " 'Strawberry___healthy',\n",
       " 'Tomato___Bacterial_spot',\n",
       " 'Tomato___Early_blight',\n",
       " 'Tomato___Late_blight',\n",
       " 'Tomato___Leaf_Mold',\n",
       " 'Tomato___Septoria_leaf_spot',\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
       " 'Tomato___Target_Spot',\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
       " 'Tomato___Tomato_mosaic_virus',\n",
       " 'Tomato___healthy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:55.894354Z",
     "iopub.status.busy": "2024-09-29T09:55:55.893457Z",
     "iopub.status.idle": "2024-09-29T09:55:55.920033Z",
     "shell.execute_reply": "2024-09-29T09:55:55.919294Z",
     "shell.execute_reply.started": "2024-09-29T09:55:55.894311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:55:59.632048Z",
     "iopub.status.busy": "2024-09-29T09:55:59.631406Z",
     "iopub.status.idle": "2024-09-29T09:55:59.636677Z",
     "shell.execute_reply": "2024-09-29T09:55:59.635724Z",
     "shell.execute_reply.started": "2024-09-29T09:55:59.632009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:56:03.581603Z",
     "iopub.status.busy": "2024-09-29T09:56:03.580465Z",
     "iopub.status.idle": "2024-09-29T09:56:03.591448Z",
     "shell.execute_reply": "2024-09-29T09:56:03.590556Z",
     "shell.execute_reply.started": "2024-09-29T09:56:03.581558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN_Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Classification, self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)       # first convolutional layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)            # first pooling layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)      # second convolutional layer\n",
    "        self.fc1 = nn.Linear(64 * 37 * 37, 128)                                 # 37 x 37 is the size after pooling\n",
    "        self.fc2 = nn.Linear(128, len(dataset.classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)                                                 # flatten all dimensions\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:56:06.970925Z",
     "iopub.status.busy": "2024-09-29T09:56:06.970431Z",
     "iopub.status.idle": "2024-09-29T09:56:07.093822Z",
     "shell.execute_reply": "2024-09-29T09:56:07.092787Z",
     "shell.execute_reply.started": "2024-09-29T09:56:06.970888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CNN_Model = CNN_Classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T09:56:10.936378Z",
     "iopub.status.busy": "2024-09-29T09:56:10.935495Z",
     "iopub.status.idle": "2024-09-29T09:56:10.940889Z",
     "shell.execute_reply": "2024-09-29T09:56:10.939906Z",
     "shell.execute_reply.started": "2024-09-29T09:56:10.936334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_Model.parameters(), lr=0.001)          # Defines the optimizer, Adam with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T09:19:38.253629Z",
     "iopub.status.busy": "2024-09-28T09:19:38.252776Z",
     "iopub.status.idle": "2024-09-28T12:52:12.643545Z",
     "shell.execute_reply": "2024-09-28T12:52:12.642575Z",
     "shell.execute_reply.started": "2024-09-28T09:19:38.253583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.8420367240905762\n",
      "Epoch 2/5, Loss: 0.13923266530036926\n",
      "Epoch 3/5, Loss: 0.007987145334482193\n",
      "Epoch 4/5, Loss: 0.010538074187934399\n",
      "Epoch 5/5, Loss: 0.0013543072855100036\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = CNN_Model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T12:55:09.077238Z",
     "iopub.status.busy": "2024-09-28T12:55:09.076879Z",
     "iopub.status.idle": "2024-09-28T12:58:05.474032Z",
     "shell.execute_reply": "2024-09-28T12:58:05.473096Z",
     "shell.execute_reply.started": "2024-09-28T12:55:09.077177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.46 %\n",
      "Precision: 87.8696%\n",
      "Recall: 87.4579%\n",
      "F1-score: 87.3738%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "CNN_Model.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = CNN_Model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T10:04:27.436727Z",
     "iopub.status.busy": "2024-09-29T10:04:27.436341Z",
     "iopub.status.idle": "2024-09-29T10:04:27.463810Z",
     "shell.execute_reply": "2024-09-29T10:04:27.462759Z",
     "shell.execute_reply.started": "2024-09-29T10:04:27.436680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Apple___Cedar_apple_rust\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open('D:/Capstone_MiniProjects_Guvi/Final_Pros/Plant-Disease-Detection-from-Images-main/Plant-Disease-Detection-from-Images-main/plant_diseases_subset/Apple___Cedar_apple_rust/0a41c25a-f9a6-4c34-8e5c-7f89a6ac4c40___FREC_C.Rust 9807.jpg')\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# Pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f'Predicted class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T13:00:33.566519Z",
     "iopub.status.busy": "2024-09-28T13:00:33.566115Z",
     "iopub.status.idle": "2024-09-28T13:00:33.595334Z",
     "shell.execute_reply": "2024-09-28T13:00:33.594435Z",
     "shell.execute_reply.started": "2024-09-28T13:00:33.566478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Apple___Cedar_apple_rust\n"
     ]
    }
   ],
   "source": [
    "# Load a test image and preprocess it\n",
    "img = Image.open('D:/Capstone_MiniProjects_Guvi/Final_Pros/Plant-Disease-Detection-from-Images-main/Plant-Disease-Detection-from-Images-main/plant_diseases_subset/Apple___Cedar_apple_rust/0a41c25a-f9a6-4c34-8e5c-7f89a6ac4c40___FREC_C.Rust 9807_90deg.JPG')\n",
    "img = transform(img).unsqueeze(0)  # add batch dimension\n",
    "\n",
    "# Pass the image through the model\n",
    "CNN_Model.eval()\n",
    "output = CNN_Model(img)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f'Predicted class: {dataset.classes[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T13:01:32.796715Z",
     "iopub.status.busy": "2024-09-28T13:01:32.795984Z",
     "iopub.status.idle": "2024-09-28T13:01:32.854098Z",
     "shell.execute_reply": "2024-09-28T13:01:32.853340Z",
     "shell.execute_reply.started": "2024-09-28T13:01:32.796666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(CNN_Model.state_dict(), 'cnn_model.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T10:02:02.593296Z",
     "iopub.status.busy": "2024-09-29T10:02:02.592393Z",
     "iopub.status.idle": "2024-09-29T10:02:03.084182Z",
     "shell.execute_reply": "2024-09-29T10:02:03.083235Z",
     "shell.execute_reply.started": "2024-09-29T10:02:02.593250Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_Model.load_state_dict(torch.load('D:\\Capstone_MiniProjects_Guvi\\Final_Pros\\Plant-Disease-Detection-from-Images-main\\Plant-Disease-Detection-from-Images-main\\cnn_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T13:06:31.783305Z",
     "iopub.status.busy": "2024-09-28T13:06:31.782457Z",
     "iopub.status.idle": "2024-09-28T13:15:15.807236Z",
     "shell.execute_reply": "2024-09-28T13:15:15.806260Z",
     "shell.execute_reply.started": "2024-09-28T13:06:31.783260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Karthik/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528M/528M [02:48<00:00, 3.29MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.0158711671829224\n",
      "Epoch 2/5, Loss: 1.1700907945632935\n",
      "Epoch 3/5, Loss: 0.016897844150662422\n",
      "Epoch 4/5, Loss: 2.289205551147461\n",
      "Epoch 5/5, Loss: 0.61502605676651\n",
      "Finished Training VGG16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# Freeze all the layers (optional, if you don't want to train the convolutional layers)\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "vgg16.classifier[6] = nn.Linear(4096, len(dataset.classes))  # 4096 is the input to the last layer\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "vgg16.classifier = vgg16.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move criterion to GPU\n",
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T13:15:49.514108Z",
     "iopub.status.busy": "2024-09-28T13:15:49.513295Z",
     "iopub.status.idle": "2024-09-28T13:17:01.522162Z",
     "shell.execute_reply": "2024-09-28T13:17:01.521228Z",
     "shell.execute_reply.started": "2024-09-28T13:15:49.514069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.64 %\n",
      "Precision: 86.6324%\n",
      "Recall: 85.6418%\n",
      "F1-score: 85.3993%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation mode\n",
    "vgg16.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = vgg16(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.4f}%')\n",
    "print(f'Recall: {recall * 100:.4f}%')\n",
    "print(f'F1-score: {f1 * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T11:00:03.458927Z",
     "iopub.status.busy": "2024-09-29T11:00:03.458139Z",
     "iopub.status.idle": "2024-09-29T11:08:10.325598Z",
     "shell.execute_reply": "2024-09-29T11:08:10.324572Z",
     "shell.execute_reply.started": "2024-09-29T11:00:03.458885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\Karthik/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233M/233M [01:13<00:00, 3.33MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 43.58063888549805\n",
      "Epoch 2/5, Loss: 10.098589897155762\n",
      "Epoch 3/5, Loss: 14.871909141540527\n",
      "Epoch 4/5, Loss: 46.39433288574219\n",
      "Epoch 5/5, Loss: 5.143483638763428\n",
      "Finished Training AlexNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained AlexNet model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Freeze layers if desired\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "alexnet.classifier[6] = nn.Linear(4096, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "alexnet.classifier = alexnet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T11:08:21.235552Z",
     "iopub.status.busy": "2024-09-29T11:08:21.234726Z",
     "iopub.status.idle": "2024-09-29T11:09:04.482545Z",
     "shell.execute_reply": "2024-09-29T11:09:04.481482Z",
     "shell.execute_reply.started": "2024-09-29T11:08:21.235513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.51 %\n",
      "Precision: 88.20%\n",
      "Recall: 87.51%\n",
      "F1-score: 87.38%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "alexnet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = alexnet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T11:45:26.496006Z",
     "iopub.status.busy": "2024-09-29T11:45:26.495340Z",
     "iopub.status.idle": "2024-09-29T11:56:32.493092Z",
     "shell.execute_reply": "2024-09-29T11:56:32.491973Z",
     "shell.execute_reply.started": "2024-09-29T11:45:26.495966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\Karthik/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Karthik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 30.8M/30.8M [00:09<00:00, 3.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 3.1420345306396484\n",
      "Epoch 2/4, Loss: 0.5805450677871704\n",
      "Epoch 3/4, Loss: 0.0\n",
      "Epoch 4/4, Loss: 7.964588642120361\n",
      "Finished Training DenseNet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load pre-trained DenseNet121 model\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "# Transfer model to the GPU\n",
    "densenet = densenet.to(device)\n",
    "\n",
    "# Freeze all the layers if you don't want to train the convolutional layers (optional)\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit the number of classes in your dataset\n",
    "num_ftrs = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "# Transfer classifier changes to the GPU\n",
    "densenet.classifier = densenet.classifier.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = optim.Adam(densenet.parameters(), lr=0.02)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        # Transfer images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = densenet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training DenseNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T11:56:39.373778Z",
     "iopub.status.busy": "2024-09-29T11:56:39.372918Z",
     "iopub.status.idle": "2024-09-29T11:57:51.584408Z",
     "shell.execute_reply": "2024-09-29T11:57:51.583435Z",
     "shell.execute_reply.started": "2024-09-29T11:56:39.373723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.27 %\n",
      "Precision: 89.99%\n",
      "Recall: 88.27%\n",
      "F1-score: 88.21%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Switch to evaluation model\n",
    "# densenet.eval()\n",
    "\n",
    "# Initialize variables for storing predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Correct and total for accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradients needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "      \n",
    "        # Forward pass to get predictions\n",
    "        outputs = densenet(images.to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update accuracy calculations\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "        # Collect predictions and true labels for other metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f} %')\n",
    "\n",
    "# Calculate precision, recall, and F1-score using sklearn\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-score: {f1 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T11:58:16.967337Z",
     "iopub.status.busy": "2024-09-29T11:58:16.966949Z",
     "iopub.status.idle": "2024-09-29T11:58:17.511374Z",
     "shell.execute_reply": "2024-09-29T11:58:17.510434Z",
     "shell.execute_reply.started": "2024-09-29T11:58:16.967300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'vgg16.pth')  \n",
    "torch.save(alexnet.state_dict(), 'alexnet_model.pth') \n",
    "torch.save(densenet.state_dict(), 'densenet.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 127499,
     "modelInstanceId": 103268,
     "sourceId": 122706,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
